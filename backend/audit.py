import logging
import io
import sys
import os

# [FIX] å¼ºåˆ¶ä½¿ç”¨ HuggingFace å›½å†…é•œåƒï¼Œè§£å†³å›½å†…ç½‘ç»œæ— æ³•ä¸‹è½½ AI æ¨¡å‹çš„é—®é¢˜
# å¿…é¡»åœ¨å¯¼å…¥ transformers ä¹‹å‰è®¾ç½®
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

import tempfile
from PIL import Image
import numpy as np

# [ä¼˜åŒ–] å»¶è¿Ÿå¯¼å…¥: ä¸è¦åœ¨æ–‡ä»¶å¼€å¤´å¯¼å…¥ PyTorch/NudeNet/Transformers
# å¦åˆ™ä¼šå¯¼è‡´æœåŠ¡å¯åŠ¨ææ…¢ï¼Œç”šè‡³åœ¨ä½å†…å­˜æœåŠ¡å™¨ä¸Šç›´æ¥ OOM
# from nudenet import NudeDetector
# from transformers ...

# è®¾ç½®æ—¥å¿— (å¼ºåˆ¶é…ç½®åˆ°æ ‡å‡†è¾“å‡ºï¼Œç¡®ä¿ç”¨æˆ·èƒ½çœ‹è§)
logging.basicConfig(level=logging.INFO, stream=sys.stdout)
logger = logging.getLogger(__name__)

# å‚è€ƒåœ°å›¾è·¯å¾„ (ç”¨äºå°æ¹¾æ£€æµ‹)
REFERENCE_MAP_PATH = os.path.join(os.path.dirname(__file__), "data", "reference_china_map.jpg")

# å…¨å±€æ¨¡å‹å•ä¾‹
_nude_detector = None
# Chinese-CLIP (æ”¿æ²»å†…å®¹)
_chinese_clip_model = None
_chinese_clip_processor = None
# OpenAI CLIP (é€šç”¨å†…å®¹)
_openai_clip_model = None
_openai_clip_processor = None
# å‚è€ƒåœ°å›¾ç¼“å­˜
_reference_map = None

UNSAFE_NUDENET_LABELS = {
    "BUTTOCKS_EXPOSED",
    "FEMALE_BREAST_EXPOSED",
    "FEMALE_GENITALIA_EXPOSED",
    "MALE_GENITALIA_EXPOSED",
    "ANUS_EXPOSED",
}

# [Safe] ç™½åå• (ä¸­æ–‡)
# å‘Šè¯‰ AI å“ªäº›ä¸œè¥¿æ˜¯å®‰å…¨çš„ï¼Œé˜²æ­¢è¯¯åˆ¤
SAFE_LABELS = [
    "è‡ªç„¶é£æ™¯",
    "åŸå¸‚è¡—é“æˆ–å»ºç­‘",
    "è‰ºæœ¯ç”»ä½œæˆ–æ’ç”»",
    "æ™®é€šäººåƒ", 
    "æ”¿æ²»äººç‰©æˆ–æ–°é—»ç…§ç‰‡",        # å¯¹åº” politicians
    "å¹³é¢è®¾è®¡æµ·æŠ¥",             # å¯¹åº” poster
    "æ¸¸æˆæˆªå›¾æˆ–CGç”»é¢",         # å¯¹åº” video game
    "ç‰¹æ•ˆåŒ–å¦†æˆ–ä¸‡åœ£èŠ‚è£…æ‰®",     # å¯¹åº” clown/costume
    "æ‹¼è´´è‰ºæœ¯æˆ–é©¬èµ›å…‹é£æ ¼",     # [Fix] é˜²æ­¢æ‹¼å›¾/é©¬èµ›å…‹è¢«è¯¯åˆ¤ä¸ºè‰²æƒ…
    "ç°ä»£è‰ºæœ¯æˆ–æŠ½è±¡ç”»",         # [Fix] å¢å¼ºè‰ºæœ¯è¯†åˆ«
    "åƒç´ ç”»æˆ–ç½‘æ ¼å›¾æ¡ˆ",         # [Fix] å¢å¼ºé©¬èµ›å…‹è¯†åˆ«
    "äººè„¸ç‰¹å†™",                 # [Fix] é˜²æ­¢å¤§è„¸ç‰¹å†™è¢«è¯¯åˆ¤
    "ç¾é£Ÿ",
    "å¯çˆ±çš„åŠ¨ç‰©",
    "ä¸–ç•Œåœ°å›¾æˆ–ä¸­å›½åœ°å›¾",        # æ™®é€šåœ°å›¾æ”¾è¡Œ
    "ä¸­æ–‡æ–°é—»æŠ¥é“æˆ–åª’ä½“æˆªå›¾",    # [Fix] é˜²æ­¢æ–°é—»è¢«è¯¯åˆ¤ä¸ºååå®£ä¼ 
    "ç¤¾ä¼šæ–°é—»äº‹ä»¶æŠ¥é“",          # [Fix] ç¤¾ä¼šæ–°é—»
    "ç”µå½±æˆ–ç”µè§†å‰§æˆªå›¾",          # [Fix] å½±è§†å†…å®¹
    "è§†é¢‘å°é¢æˆ–ç¼©ç•¥å›¾"           # [Fix] è§†é¢‘å†…å®¹
]

# ==================== Chinese-CLIP æ ‡ç­¾ (ä¸­å›½æ”¿æ²»å†…å®¹) ====================
CHINESE_SAFE_LABELS = [
    "è‡ªç„¶é£æ™¯", "åŸå¸‚è¡—é“æˆ–å»ºç­‘", "è‰ºæœ¯ç”»ä½œæˆ–æ’ç”»", "æ™®é€šäººåƒ",
    "æ”¿æ²»äººç‰©æˆ–æ–°é—»ç…§ç‰‡", "æ¸¸æˆæˆªå›¾æˆ–CGç”»é¢", "ç”µå½±æˆ–ç”µè§†å‰§æˆªå›¾",
    "åœ°å›¾", "æ ‡å‡†ä¸–ç•Œåœ°å›¾", "å›½æ——æˆ–å¤–å›½æ——å¸œ",  # [Fix] ç”¨é€šç”¨"åœ°å›¾"æ›¿ä»£å…·ä½“æè¿°
    "èŠå¤©è®°å½•æˆ–æ–‡å­—æˆªå›¾", "è¡¨æƒ…åŒ…æˆ–æç¬‘å›¾ç‰‡", "äº§å“è¯´æ˜ä¹¦æˆ–å•æ®",
    "ä»£ç æˆ–ç¨‹åºç•Œé¢", "æ‰‹æœºæˆ–ç”µè„‘å±å¹•", "æ±½è½¦æˆ–äº¤é€šå·¥å…·",
    "ç¾é£Ÿæˆ–é¥®æ–™", "å¯çˆ±çš„åŠ¨ç‰©", "å®¶å…·æˆ–å®¤å†…è®¾è®¡",
    "æŠ½è±¡èƒŒæ™¯æˆ–çº¹ç†", "ä½“è‚²è¿åŠ¨æˆ–å¥èº«", "åŠ¨æ¼«æˆ–äºŒæ¬¡å…ƒå›¾ç‰‡"
]

CHINESE_UNSAFE_LABELS = [
    # "ä¸€å¼ ç¼ºå°‘å°æ¹¾çš„é”™è¯¯ä¸­å›½åœ°å›¾",  # [å·²ç¦ç”¨] æ”¹ç”¨æ¨¡æ¿åŒ¹é…æ£€æµ‹
    "å°ç‹¬æ¸¯ç‹¬è—ç‹¬æ——å¸œ",     # åˆ†è£‚ä¸»ä¹‰æ——å¸œ
]

CHINESE_ALL_LABELS = CHINESE_SAFE_LABELS + CHINESE_UNSAFE_LABELS

# ==================== OpenAI CLIP æ ‡ç­¾ (é€šç”¨å†…å®¹æ£€æµ‹ - è‹±æ–‡) ====================
OPENAI_SAFE_LABELS = [
    "a natural landscape photo",
    "a video game screenshot",
    "a movie or TV show scene",
    "a news photo",
    "a normal portrait photo",
    "a food photo",
    "an art painting",
    "a national flag",
    "a world map",              
    "a map of national flags",
    "a meme or funny picture",
    "a screenshot of text or chat",
    "a receipt or document",
    "computer code or screen",
    "a car or vehicle",
    "a cat or dog",
    "a close-up of an object",
    "a sports photo",
    "an anime or cartoon image",
    "a logo or icon"
]

OPENAI_UNSAFE_LABELS = [
    "ISIS terrorist flag or propaganda",    # ææ€–ç»„ç»‡æ——å¸œ/å®£ä¼ 
    "real beheading or execution video",    # çœŸå®æ–©é¦–/å¤„å†³è§†é¢‘
    "illegal drug dealing scene",           # æ¯’å“äº¤æ˜“åœºæ™¯
    "bloody gore or dead body",             # è¡€è…¥/å°¸ä½“
]

OPENAI_ALL_LABELS = OPENAI_SAFE_LABELS + OPENAI_UNSAFE_LABELS

def check_taiwan_region(image: Image.Image) -> dict:
    """
    æ£€æµ‹ä¸­å›½åœ°å›¾æ˜¯å¦åŒ…å«å°æ¹¾
    é€šè¿‡å¯¹æ¯”å°æ¹¾åŒºåŸŸå’Œå¤§é™†åŒºåŸŸçš„é¢œè‰²æ¥åˆ¤æ–­
    è¿”å›: {"is_map": bool, "has_taiwan": bool, "color_match": float}
    """
    global _reference_map
    
    try:
        # åŠ è½½å‚è€ƒåœ°å›¾
        if _reference_map is None:
            if os.path.exists(REFERENCE_MAP_PATH):
                _reference_map = Image.open(REFERENCE_MAP_PATH).convert("RGB")
                print(f"âœ… [åœ°å›¾æ£€æµ‹] å‚è€ƒåœ°å›¾å·²åŠ è½½", flush=True)
            else:
                print(f"âš ï¸ [åœ°å›¾æ£€æµ‹] å‚è€ƒåœ°å›¾ä¸å­˜åœ¨: {REFERENCE_MAP_PATH}", flush=True)
                return {"is_map": False, "has_taiwan": True, "color_match": 1.0}
        
        # ä¿æŒæ¯”ä¾‹ç¼©æ”¾åˆ° 800 å®½åº¦
        original_w, original_h = image.size
        scale = 800 / original_w
        new_h = int(original_h * scale)
        img_resized = image.convert("RGB").resize((800, new_h), Image.Resampling.LANCZOS)
        
        # å®šä¹‰åŒºåŸŸ (ç›¸å¯¹åæ ‡ï¼Œæ ¹æ®ä¸­å›½åœ°å›¾çš„æ ‡å‡†æ¯”ä¾‹)
        # å°æ¹¾åŒºåŸŸ: å³ä¾§åä¸‹ (å¤§çº¦åœ¨ x: 82%-92%, y: 55%-72%)
        taiwan_box = (
            int(800 * 0.82),      # å·¦
            int(new_h * 0.55),    # ä¸Š
            int(800 * 0.92),      # å³
            int(new_h * 0.72),    # ä¸‹
        )
        
        # å¤§é™†åŒºåŸŸ: ä¸­éƒ¨ (ä½œä¸ºå‚è€ƒé™†åœ°é¢œè‰²)
        mainland_box = (
            int(800 * 0.45),      # å·¦
            int(new_h * 0.35),    # ä¸Š
            int(800 * 0.60),      # å³
            int(new_h * 0.50),    # ä¸‹
        )
        
        taiwan_region = img_resized.crop(taiwan_box)
        mainland_region = img_resized.crop(mainland_box)
        
        # è·å–èƒŒæ™¯é¢œè‰² (å·¦ä¸Šè§’ï¼Œé€šå¸¸æ˜¯æµ·æ´‹/ç™½è‰²)
        background_box = (0, 0, 50, 50)
        background_region = img_resized.crop(background_box)
        
        # è®¡ç®—å¹³å‡é¢œè‰²
        taiwan_arr = np.array(taiwan_region).astype(float)
        mainland_arr = np.array(mainland_region).astype(float)
        background_arr = np.array(background_region).astype(float)
        
        taiwan_avg_color = np.mean(taiwan_arr, axis=(0, 1))
        mainland_avg_color = np.mean(mainland_arr, axis=(0, 1))
        background_avg_color = np.mean(background_arr, axis=(0, 1))
        
        # è®¡ç®—å°æ¹¾ä¸èƒŒæ™¯çš„é¢œè‰²å·®å¼‚
        taiwan_vs_background = np.sqrt(np.sum((taiwan_avg_color - background_avg_color) ** 2))
        # è®¡ç®—å¤§é™†ä¸èƒŒæ™¯çš„é¢œè‰²å·®å¼‚ (ä½œä¸ºå‚è€ƒ)
        mainland_vs_background = np.sqrt(np.sum((mainland_avg_color - background_avg_color) ** 2))
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦åƒåœ°å›¾ 
        img_gray = np.array(img_resized.convert("L"))
        light_ratio = np.mean(img_gray > 200) 
        is_likely_map = light_ratio > 0.20  # é™ä½é˜ˆå€¼ï¼Œé€‚åº”å½©è‰²åœ°å›¾
        
        # åˆ¤æ–­å°æ¹¾æ˜¯å¦å­˜åœ¨:
        # 1. å°æ¹¾é¢œè‰²è¦å’ŒèƒŒæ™¯ä¸åŒ (å·®å¼‚ > 30)
        # 2. å¦‚æœå¤§é™†å’ŒèƒŒæ™¯å·®å¼‚å¾ˆå¤§ï¼Œå°æ¹¾ä¹Ÿåº”è¯¥å’ŒèƒŒæ™¯æœ‰å·®å¼‚
        taiwan_brightness = float(np.mean(taiwan_arr))
        has_taiwan = taiwan_vs_background > 30  # å°æ¹¾é¢œè‰²å’ŒèƒŒæ™¯å·®å¼‚è¦ > 30
        
        print(f"ğŸ—ºï¸ [åœ°å›¾æ£€æµ‹] æ˜¯åœ°å›¾: {is_likely_map}", flush=True)
        print(f"   èƒŒæ™¯é¢œè‰²: {background_avg_color.astype(int)}", flush=True)
        print(f"   å¤§é™†é¢œè‰²: {mainland_avg_color.astype(int)} (ä¸èƒŒæ™¯å·®: {mainland_vs_background:.0f})", flush=True)
        print(f"   å°æ¹¾é¢œè‰²: {taiwan_avg_color.astype(int)} (ä¸èƒŒæ™¯å·®: {taiwan_vs_background:.0f})", flush=True)
        print(f"   æœ‰å°æ¹¾: {has_taiwan} (éœ€è¦å·®å¼‚ > 30)", flush=True)
        
        return {
            "is_map": bool(is_likely_map),
            "has_taiwan": bool(has_taiwan),
            "color_match": float(taiwan_vs_background / 255.0),
            "taiwan_brightness": float(taiwan_brightness)
        }
        
    except Exception as e:
        print(f"âŒ [åœ°å›¾æ£€æµ‹] é”™è¯¯: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return {"is_map": False, "has_taiwan": True, "color_match": 1.0}

def get_nude_detector():
    global _nude_detector
    if _nude_detector is None:
        print("â³ [ç³»ç»Ÿ] åˆå§‹åŒ– NudeNet...", flush=True)
        try:
            from nudenet import NudeDetector
            _nude_detector = NudeDetector()
        except ImportError as e:
            print(f"âŒ [ç³»ç»Ÿ] NudeNet å¯¼å…¥å¤±è´¥: {e}", flush=True)
            return None
    return _nude_detector

def get_chinese_clip():
    """åŠ è½½ Chinese-CLIP ç”¨äºä¸­å›½æ”¿æ²»å†…å®¹æ£€æµ‹"""
    global _chinese_clip_model, _chinese_clip_processor
    
    if _chinese_clip_model is None or _chinese_clip_processor is None:
        print("â³ [ç³»ç»Ÿ] åˆå§‹åŒ– Chinese-CLIP (é˜¿é‡Œè¾¾æ‘©é™¢ç‰ˆ)...", flush=True)
        try:
            import torch
            try:
                # ä¼˜å…ˆå°è¯•å®˜æ–¹æ¨èçš„ä¸“ç”¨ç±»
                from transformers import ChineseCLIPProcessor, ChineseCLIPModel
                ModelClass = ChineseCLIPModel
                ProcessorClass = ChineseCLIPProcessor
            except ImportError:
                # å…¼å®¹æ—§ç‰ˆæœ¬ transformersï¼šå°è¯•ä½¿ç”¨ Auto ç±»
                print("âš ï¸ [ç³»ç»Ÿ] transformers ç‰ˆæœ¬ä¸æ”¯æŒ ChineseCLIPProcessorï¼Œå°è¯•ä½¿ç”¨ AutoProcessor...", flush=True)
                from transformers import AutoProcessor, AutoModel
                ModelClass = AutoModel
                ProcessorClass = AutoProcessor

            model_id = "OFA-Sys/chinese-clip-vit-base-patch16"
            # [Fix] ä½¿ç”¨ä¸´æ—¶å˜é‡ï¼Œç¡®ä¿åŠ è½½å®Œå…¨æˆåŠŸåå†èµ‹å€¼ç»™å…¨å±€å˜é‡
            # [Fix 2] æ·»åŠ  attn_implementation='eager' è§£å†³ transformers 4.50+ çš„ meta device bug
            model = ModelClass.from_pretrained(
                model_id, 
                low_cpu_mem_usage=False,
                attn_implementation="eager"  # æ˜¾å¼ä½¿ç”¨ eager attentionï¼Œé¿å… SDPA meta bug
            )
            processor = ProcessorClass.from_pretrained(model_id)
            
            _chinese_clip_model = model
            _chinese_clip_processor = processor
            print("âœ… [ç³»ç»Ÿ] Chinese-CLIP åŠ è½½å®Œæˆ (ä¸­å›½æ”¿æ²»å†…å®¹æ£€æµ‹)", flush=True)
        except Exception as e:
            # é™çº§å¤„ç†ï¼šä¸å½±å“ä¸»æµç¨‹ï¼Œåªæ‰“å°è­¦å‘Š
            print(f"âš ï¸ [ç³»ç»Ÿ] Chinese-CLIP åŠ è½½å¤±è´¥: {e}", flush=True)
            print("   (å°†è·³è¿‡ä¸­å›½æ”¿æ²»å†…å®¹æ£€æµ‹ï¼Œä»…ä½¿ç”¨ OpenAI CLIP)", flush=True)
            # ç¡®ä¿å…¨å±€å˜é‡é‡ç½®ä¸º Noneï¼Œé˜²æ­¢éƒ¨åˆ†åŠ è½½
            _chinese_clip_model = None
            _chinese_clip_processor = None
            return None, None
    return _chinese_clip_model, _chinese_clip_processor

def get_openai_clip():
    """åŠ è½½ OpenAI CLIP ç”¨äºé€šç”¨å†…å®¹æ£€æµ‹ (æš´åŠ›/ææ€–ç­‰)"""
    global _openai_clip_model, _openai_clip_processor
        
    if _openai_clip_model is None or _openai_clip_processor is None:
        print("â³ [ç³»ç»Ÿ] åˆå§‹åŒ– OpenAI CLIP...", flush=True)
        try:
            # [Lazy Import]
            from transformers import CLIPProcessor, CLIPModel
            import torch

            model_id = "openai/clip-vit-base-patch32"
            # [FIX] ä½¿ç”¨ä¸´æ—¶å˜é‡ï¼Œé˜²æ­¢éƒ¨åˆ†åŠ è½½å¯¼è‡´å…¨å±€çŠ¶æ€ä¸ä¸€è‡´
            # æ·»åŠ  device_map=None é˜²æ­¢ accelerate è‡ªåŠ¨å°†æ¨¡å‹æ”¾åˆ° meta device
            model = CLIPModel.from_pretrained(model_id, low_cpu_mem_usage=False, device_map=None)
            model.to('cpu') # æ˜¾å¼ç§»åŠ¨åˆ° CPU
            processor = CLIPProcessor.from_pretrained(model_id)
            
            _openai_clip_model = model
            _openai_clip_processor = processor
            print("âœ… [ç³»ç»Ÿ] OpenAI CLIP åŠ è½½å®Œæˆ (é€šç”¨å†…å®¹æ£€æµ‹)", flush=True)
        except Exception as e:
            print(f"âŒ [ç³»ç»Ÿ] OpenAI CLIP åŠ è½½å¤±è´¥: {e}", flush=True)
            _openai_clip_model = None
            _openai_clip_processor = None
            return None, None
    return _openai_clip_model, _openai_clip_processor

def check_image_safety(content: bytes, threshold: float = 0.50) -> dict:
    # å¼ºåˆ¶æ‰“å°ï¼Œç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ°
    print("\nğŸ” [Audit] å¼€å§‹æ–°ä¸€è½®å›¾ç‰‡å®¡è®¡ (Powered by NudeNet & CLIP & åœ°å›¾æ£€æµ‹)...", flush=True)
    
    # [FIX] è§£å†³ check_image_safety ä¸­ä½¿ç”¨ torch.no_grad() ä½†æœªå¯¼å…¥ torch çš„é—®é¢˜
    try:
        import torch
    except ImportError:
        print("âŒ [ç³»ç»Ÿ] æ— æ³•å¯¼å…¥ torch, AI å®¡æ ¸å°†å—é™", flush=True)

    result = {"safe": True, "score": 0.0, "reason": "Pass", "details": {}}
    
    # --- 0. åœ°å›¾æ£€æµ‹ (å·²ç¦ç”¨ - è¯¯åˆ¤ç‡å¤ªé«˜) ---
    # æ¨¡æ¿åŒ¹é…æ–¹æ¡ˆæ— æ³•å¯é æ£€æµ‹åœ°å›¾ï¼Œæš‚æ—¶ç¦ç”¨
    # å¦‚éœ€å¯ç”¨ï¼Œè¯·ä½¿ç”¨ Vision API æ–¹æ¡ˆ
    # try:
    #     image = Image.open(io.BytesIO(content))
    #     map_result = check_taiwan_region(image)
    #     ...
    # except Exception as e:
    #     print(f"âš ï¸ [åœ°å›¾æ£€æµ‹] è·³è¿‡: {e}", flush=True)
    # --- 1. NudeNet æ£€æµ‹ (é€»è¾‘ä¸å˜) ---
    try:
        temp_path = None
        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
            # [FIX] ä½¿ç”¨ Pillow ç»Ÿä¸€è½¬æ¢ä¸º JPGï¼Œé˜²æ­¢ OpenCV è¯»å– WebP/AVIF å¤±è´¥å¯¼è‡´ NoneType é”™è¯¯
            try:
                img_pil = Image.open(io.BytesIO(content))
                if img_pil.mode != "RGB":
                    img_pil = img_pil.convert("RGB")
                img_pil.save(tmp, format="JPEG")
            except Exception:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼ˆæå°‘æƒ…å†µï¼‰ï¼Œå°è¯•ç›´æ¥å†™å…¥åŸæ•°æ®
                tmp.write(content)
            temp_path = tmp.name
        
        detector = get_nude_detector()
        detections = detector.detect(temp_path)
        
        unsafe_items = []
        max_score = 0.0
        
        print("ğŸ§  [NudeNet] è¯¦ç»†æ£€æµ‹ç»“æœ:", flush=True)
        if not detections:
            print("   (æœªæ£€æµ‹åˆ°ä»»ä½•äººä½“/å™¨å®˜ç‰¹å¾)", flush=True)
        else:
            for item in detections:
                print(f"   {item['class']}: {item['score']:.4f}", flush=True)
            
        for item in detections:
            if item["class"] in UNSAFE_NUDENET_LABELS and item["score"] > 0.60: # ä¿æŒ 0.60
                unsafe_items.append(f"{item['class']}({round(item['score'],2)})")
                max_score = max(max_score, item["score"])
        
        if unsafe_items:
            print(f"ğŸš« [NudeNet] æ‹¦æˆª: {', '.join(unsafe_items)}")
            if os.path.exists(temp_path): os.remove(temp_path)
            return {
                "safe": False,
                "score": max_score,
                "reason": f"åŒ…å«è£¸éœ²å†…å®¹: {', '.join(unsafe_items)}",
                "details": {"nudenet": detections}
            }
        else:
            print("âœ… [NudeNet] é€šè¿‡")
            
    except Exception as e:
        error_msg = f"NudeNet Error: {str(e)}"
        print(f"âŒ [NudeNet] é”™è¯¯: {e}")
        result["details"]["nudenet_error"] = error_msg
    finally:
        if temp_path and os.path.exists(temp_path): os.remove(temp_path)

    # --- 2. Chinese-CLIP æ£€æµ‹ (ä¸­å›½æ”¿æ²»å†…å®¹) ---
    # [Lazy Import] ç§»é™¤å…¨å±€ HAS_CLIP æ£€æŸ¥
    try:
        model, processor = get_chinese_clip()
        if model and processor:
                image = Image.open(io.BytesIO(content))
                inputs = processor(text=CHINESE_ALL_LABELS, images=image, return_tensors="pt", padding=True)
                
                with torch.no_grad():
                    outputs = model(**inputs)
                
                probs = outputs.logits_per_image.softmax(dim=1)
                probs_list = probs[0].tolist()
                
                sorted_probs = sorted(zip(CHINESE_ALL_LABELS, probs_list), key=lambda x: x[1], reverse=True)
                print("-" * 30)
                print("ğŸ§  [Chinese-CLIP] ä¸­å›½æ”¿æ²»å†…å®¹æ£€æµ‹:")
                for l, p in sorted_probs[:3]:
                    print(f"   {l:<20}: {p:.4f}")
                
                max_prob = sorted_probs[0][1]
                max_label = sorted_probs[0][0]
                
                # [Fix] åˆ†ç±»åˆ«é˜ˆå€¼ï¼šåœ°å›¾æ£€æµ‹æ›´æ•æ„Ÿï¼Œæ——å¸œæ£€æµ‹æ›´ä¸¥æ ¼
                THRESHOLDS = {
                    "ä¸€å¼ ç¼ºå°‘å°æ¹¾çš„é”™è¯¯ä¸­å›½åœ°å›¾": 0.40,  # åœ°å›¾æ£€æµ‹éœ€è¦æ›´æ•æ„Ÿ
                    "å°ç‹¬æ¸¯ç‹¬è—ç‹¬æ——å¸œ": 0.60,            # æ——å¸œæ£€æµ‹ä¿æŒä¸¥æ ¼
                }
                
                if max_label in CHINESE_UNSAFE_LABELS:
                    threshold = THRESHOLDS.get(max_label, 0.50)  # é»˜è®¤0.50
                    if max_prob > threshold:
                        print(f"ğŸš« [Chinese-CLIP] æ”¿æ²»é—®é¢˜! å‘½ä¸­: {max_label} (Score: {max_prob:.2f}, é˜ˆå€¼: {threshold})", flush=True)
                        return {
                            "safe": False,
                            "score": max_prob,
                            "reason": f"æ”¿æ²»æ•æ„Ÿ: {max_label}",
                            "details": {"chinese_clip": dict(zip(CHINESE_ALL_LABELS, probs_list))}
                        }
                    else:
                        print(f"ğŸ“Š [Chinese-CLIP] æœªè¾¾é˜ˆå€¼ (TOP: {max_label}, Score: {max_prob:.2f} < {threshold})", flush=True)
                else:
                    print(f"ğŸ“Š [Chinese-CLIP] é€šè¿‡ (TOP: {max_label})", flush=True)
                result["details"]["chinese_clip"] = dict(zip(CHINESE_ALL_LABELS, probs_list))
                    
    except Exception as e:
        error_msg = f"Chinese-CLIP Error: {str(e)}"
        print(f"âŒ [Chinese-CLIP] é”™è¯¯: {e}", flush=True)
        import traceback
        traceback.print_exc()
        result["details"]["chinese_clip_error"] = error_msg

    # --- 3. OpenAI CLIP æ£€æµ‹ (é€šç”¨å†…å®¹: ææ€–/æš´åŠ›/æ¯’å“) ---
    # [Lazy Import] ç§»é™¤å…¨å±€ HAS_CLIP æ£€æŸ¥
    try:
        model, processor = get_openai_clip()
        if model and processor:
                image = Image.open(io.BytesIO(content))
                inputs = processor(text=OPENAI_ALL_LABELS, images=image, return_tensors="pt", padding=True)
                
                with torch.no_grad():
                    outputs = model(**inputs)
                
                probs = outputs.logits_per_image.softmax(dim=1)
                probs_list = probs[0].tolist()
                
                sorted_probs = sorted(zip(OPENAI_ALL_LABELS, probs_list), key=lambda x: x[1], reverse=True)
                print("-" * 30)
                print("ğŸ§  [OpenAI-CLIP] é€šç”¨å†…å®¹æ£€æµ‹:")
                for l, p in sorted_probs[:3]:
                    print(f"   {l:<40}: {p:.4f}")
                
                max_prob = sorted_probs[0][1]
                max_label = sorted_probs[0][0]
                
                GENERAL_THRESHOLD = 0.50
                if max_label in OPENAI_UNSAFE_LABELS and max_prob > GENERAL_THRESHOLD:
                    print(f"ğŸš« [OpenAI-CLIP] å±é™©å†…å®¹! å‘½ä¸­: {max_label} (Score: {max_prob:.2f})", flush=True)
                    return {
                        "safe": False,
                        "score": max_prob,
                        "reason": f"å±é™©å†…å®¹: {max_label}",
                        "details": {"openai_clip": dict(zip(OPENAI_ALL_LABELS, probs_list))}
                    }
                else:
                    print(f"ğŸ“Š [OpenAI-CLIP] é€šè¿‡ (TOP: {max_label})", flush=True)
                    result["details"]["openai_clip"] = dict(zip(OPENAI_ALL_LABELS, probs_list))
                    
    except Exception as e:
        error_msg = f"OpenAI-CLIP Error: {str(e)}"
        print(f"âŒ [OpenAI-CLIP] é”™è¯¯: {e}", flush=True)
        import traceback
        traceback.print_exc()
        result["details"]["openai_clip_error"] = error_msg

    return result
